{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import SimpleRNN, CuDNNLSTM, CuDNNGRU, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/train.csv')\n",
    "dataset.head()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_indexes = dataset.loc[pd.isna(dataset[\"text\"]), :].index\n",
    "dataset = dataset.drop(nan_indexes)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.text\n",
    "y = dataset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras as K\n",
    "\n",
    "def train_model(model_id, model, optimizer, epochs, X_train, y_train, validation_split, batch_size):\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('NNs/' + model_id + '-{epoch:03d}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tb_callback = K.callbacks.TensorBoard(log_dir='./new_logs/nn_' + str(model_id))\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[tb_callback, checkpoint])\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM13_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 50)          100000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 142,633\n",
      "Trainable params: 142,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 17s 1ms/step - loss: 0.3639 - acc: 0.8466 - val_loss: 0.1872 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18716, saving model to NNs/LSTM12 - 2000 words-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 494us/step - loss: 0.1996 - acc: 0.9280 - val_loss: 0.1965 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18716\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 500us/step - loss: 0.1698 - acc: 0.9392 - val_loss: 0.2360 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18716\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 502us/step - loss: 0.1454 - acc: 0.9505 - val_loss: 0.1821 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18716 to 0.18214, saving model to NNs/LSTM12 - 2000 words-004.h5\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 498us/step - loss: 0.1295 - acc: 0.9551 - val_loss: 0.1399 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18214 to 0.13989, saving model to NNs/LSTM12 - 2000 words-005.h5\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 496us/step - loss: 0.1195 - acc: 0.9597 - val_loss: 0.2084 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13989\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 500us/step - loss: 0.1059 - acc: 0.9656 - val_loss: 0.1357 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.13989 to 0.13568, saving model to NNs/LSTM12 - 2000 words-007.h5\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 473us/step - loss: 0.0891 - acc: 0.9718 - val_loss: 0.1317 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.13568 to 0.13173, saving model to NNs/LSTM12 - 2000 words-008.h5\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 493us/step - loss: 0.0892 - acc: 0.9704 - val_loss: 0.1641 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13173\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 487us/step - loss: 0.0816 - acc: 0.9733 - val_loss: 0.1725 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55243304e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM12 - 2000 words', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1000, 50)          50000     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 92,633\n",
      "Trainable params: 92,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 515us/step - loss: 0.3614 - acc: 0.8466 - val_loss: 0.2395 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23954, saving model to NNs/LSTM12 - 2000 words-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 500us/step - loss: 0.2197 - acc: 0.9196 - val_loss: 0.2098 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23954 to 0.20983, saving model to NNs/LSTM12 - 2000 words-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 502us/step - loss: 0.2126 - acc: 0.9273 - val_loss: 0.1961 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20983 to 0.19606, saving model to NNs/LSTM12 - 2000 words-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 502us/step - loss: 0.1821 - acc: 0.9367 - val_loss: 0.1784 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19606 to 0.17843, saving model to NNs/LSTM12 - 2000 words-004.h5\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 500us/step - loss: 0.1682 - acc: 0.9411 - val_loss: 0.1823 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17843\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 502us/step - loss: 0.1607 - acc: 0.9448 - val_loss: 0.1474 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17843 to 0.14744, saving model to NNs/LSTM12 - 2000 words-006.h5\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 505us/step - loss: 0.1412 - acc: 0.9536 - val_loss: 0.1984 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14744\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 491us/step - loss: 0.1337 - acc: 0.9547 - val_loss: 0.2035 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14744\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 488us/step - loss: 0.1405 - acc: 0.9538 - val_loss: 0.1307 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.14744 to 0.13074, saving model to NNs/LSTM12 - 2000 words-009.h5\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 504us/step - loss: 0.1189 - acc: 0.9595 - val_loss: 0.2237 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55418d75f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM12 - 2000 words', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 1000, 50)          25000     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 67,633\n",
      "Trainable params: 67,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 522us/step - loss: 0.4055 - acc: 0.8249 - val_loss: 0.2465 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24650, saving model to NNs/LSTM13 - 500 words-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 506us/step - loss: 0.2584 - acc: 0.9011 - val_loss: 0.2002 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24650 to 0.20022, saving model to NNs/LSTM13 - 500 words-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 506us/step - loss: 0.2401 - acc: 0.9123 - val_loss: 0.1961 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20022 to 0.19614, saving model to NNs/LSTM13 - 500 words-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 503us/step - loss: 0.2146 - acc: 0.9224 - val_loss: 0.2556 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19614\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 503us/step - loss: 0.2131 - acc: 0.9230 - val_loss: 0.2175 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19614\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 501us/step - loss: 0.2012 - acc: 0.9268 - val_loss: 0.2132 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.19614\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 501us/step - loss: 0.1797 - acc: 0.9374 - val_loss: 0.2359 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19614\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 501us/step - loss: 0.1707 - acc: 0.9380 - val_loss: 0.2398 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19614\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 503us/step - loss: 0.1833 - acc: 0.9372 - val_loss: 0.2048 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19614\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 485us/step - loss: 0.1658 - acc: 0.9386 - val_loss: 0.1525 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19614 to 0.15252, saving model to NNs/LSTM13 - 500 words-010.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5541b39278>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM13 - 500 words', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM13_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,25,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1000, 25)          12500     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 64)                23296     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 48,733\n",
      "Trainable params: 48,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 8s 484us/step - loss: 0.4407 - acc: 0.7889 - val_loss: 0.2888 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28878, saving model to NNs/LSTM13 - 25 w2v-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 465us/step - loss: 0.2599 - acc: 0.9012 - val_loss: 0.2060 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28878 to 0.20595, saving model to NNs/LSTM13 - 25 w2v-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 466us/step - loss: 0.2298 - acc: 0.9147 - val_loss: 0.1877 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20595 to 0.18771, saving model to NNs/LSTM13 - 25 w2v-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 464us/step - loss: 0.2224 - acc: 0.9187 - val_loss: 0.2027 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18771\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 472us/step - loss: 0.2135 - acc: 0.9246 - val_loss: 0.1919 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18771\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.1989 - acc: 0.9292 - val_loss: 0.2136 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18771\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.1926 - acc: 0.9329 - val_loss: 0.1789 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.18771 to 0.17886, saving model to NNs/LSTM13 - 25 w2v-007.h5\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.1866 - acc: 0.9333 - val_loss: 0.5110 - val_acc: 0.7936\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17886\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 463us/step - loss: 0.1674 - acc: 0.9412 - val_loss: 0.2224 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17886\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 460us/step - loss: 0.2033 - acc: 0.9238 - val_loss: 0.1748 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.17886 to 0.17476, saving model to NNs/LSTM13 - 25 w2v-010.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f553eb99f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM13 - 25 w2v', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM13_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 1000, 75)          37500     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_9 (CuDNNLSTM)     (None, 64)                36096     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 86,533\n",
      "Trainable params: 86,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 559us/step - loss: 0.6882 - acc: 0.5838 - val_loss: 0.6824 - val_acc: 0.7361\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68244, saving model to NNs/LSTM13 - SGD-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 530us/step - loss: 0.6641 - acc: 0.6644 - val_loss: 0.6523 - val_acc: 0.5461\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68244 to 0.65227, saving model to NNs/LSTM13 - SGD-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 531us/step - loss: 0.5894 - acc: 0.6942 - val_loss: 0.4985 - val_acc: 0.7667\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65227 to 0.49855, saving model to NNs/LSTM13 - SGD-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 9s 521us/step - loss: 0.5082 - acc: 0.7527 - val_loss: 0.6923 - val_acc: 0.6061\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49855\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 9s 528us/step - loss: 0.4759 - acc: 0.7787 - val_loss: 0.4554 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49855 to 0.45536, saving model to NNs/LSTM13 - SGD-005.h5\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 9s 530us/step - loss: 0.4569 - acc: 0.7935 - val_loss: 0.4286 - val_acc: 0.8139\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45536 to 0.42863, saving model to NNs/LSTM13 - SGD-006.h5\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 530us/step - loss: 0.4349 - acc: 0.8094 - val_loss: 0.4033 - val_acc: 0.8346\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42863 to 0.40326, saving model to NNs/LSTM13 - SGD-007.h5\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 9s 525us/step - loss: 0.4490 - acc: 0.8019 - val_loss: 0.6382 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.40326\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 9s 521us/step - loss: 0.5403 - acc: 0.7423 - val_loss: 0.5018 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.40326\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 9s 529us/step - loss: 0.4870 - acc: 0.7727 - val_loss: 0.4362 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.40326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5510300780>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM13 - SGD', model, SGD(0.1), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 1000, 75)          37500     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_10 (CuDNNLSTM)    (None, 64)                36096     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 86,533\n",
      "Trainable params: 86,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 571us/step - loss: 0.3558 - acc: 0.8460 - val_loss: 0.2000 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20004, saving model to NNs/LSTM13 - Adam-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 532us/step - loss: 0.2166 - acc: 0.9200 - val_loss: 0.1867 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20004 to 0.18669, saving model to NNs/LSTM13 - Adam-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 517us/step - loss: 0.1860 - acc: 0.9343 - val_loss: 0.1818 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.18669 to 0.18180, saving model to NNs/LSTM13 - Adam-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 9s 536us/step - loss: 0.1935 - acc: 0.9290 - val_loss: 0.1930 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18180\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 9s 528us/step - loss: 0.3066 - acc: 0.8730 - val_loss: 0.2923 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18180\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 9s 537us/step - loss: 0.2400 - acc: 0.9096 - val_loss: 0.4196 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18180\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 535us/step - loss: 0.4756 - acc: 0.7740 - val_loss: 0.4984 - val_acc: 0.7436\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18180\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 9s 538us/step - loss: 0.3662 - acc: 0.8427 - val_loss: 0.3187 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18180\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 9s 539us/step - loss: 0.2963 - acc: 0.8865 - val_loss: 0.2458 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18180\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 9s 535us/step - loss: 0.2950 - acc: 0.8873 - val_loss: 0.4828 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54c07bae80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM13 - Adam', model, Adam(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_11 (Embedding)     (None, 1000, 75)          37500     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_11 (CuDNNLSTM)    (None, 64)                36096     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 86,533\n",
      "Trainable params: 86,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 562us/step - loss: 0.3918 - acc: 0.8379 - val_loss: 0.2763 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27627, saving model to NNs/LSTM13 - RMSprop-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 527us/step - loss: 0.2612 - acc: 0.9032 - val_loss: 0.2752 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27627 to 0.27518, saving model to NNs/LSTM13 - RMSprop-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 538us/step - loss: 0.2353 - acc: 0.9137 - val_loss: 0.2666 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27518 to 0.26656, saving model to NNs/LSTM13 - RMSprop-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 9s 535us/step - loss: 0.2770 - acc: 0.8922 - val_loss: 0.2133 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26656 to 0.21331, saving model to NNs/LSTM13 - RMSprop-004.h5\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 9s 537us/step - loss: 0.2106 - acc: 0.9261 - val_loss: 0.2951 - val_acc: 0.9027\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21331\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 9s 536us/step - loss: 0.2015 - acc: 0.9321 - val_loss: 0.1904 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21331 to 0.19036, saving model to NNs/LSTM13 - RMSprop-006.h5\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 538us/step - loss: 0.2441 - acc: 0.9058 - val_loss: 0.1894 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19036 to 0.18937, saving model to NNs/LSTM13 - RMSprop-007.h5\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 9s 537us/step - loss: 0.1924 - acc: 0.9309 - val_loss: 0.1713 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18937 to 0.17130, saving model to NNs/LSTM13 - RMSprop-008.h5\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 9s 535us/step - loss: 0.2102 - acc: 0.9227 - val_loss: 0.2200 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17130\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 9s 528us/step - loss: 0.1819 - acc: 0.9324 - val_loss: 0.1785 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5484719f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM13 - RMSprop', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
