{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import SimpleRNN, CuDNNLSTM, GRU, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/train.csv')\n",
    "dataset.head()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_indexes = dataset.loc[pd.isna(dataset[\"text\"]), :].index\n",
    "dataset = dataset.drop(nan_indexes)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(142 in nan_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.text\n",
    "y = dataset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  U.N. Secretary General Complains That The ‘Masses Have Rejected Globalism’ In Favor Of Nationalism Antonio Guterres, elected in October to take over as U.N. secretary general next year, told a conference in his native Lisbon that this trend had undermined the willingness to receive refugees in Europe this year. He said the world must re-establish international protection for refugees coming from war zones such as Syria, but it would not be easy as developed countries were turning to nationalist agendas.   22, 2016 The incoming head of the United Nations warned on Tuesday that ‘losers of globalization’ in rich countries have felt ignored by establishment politicians, prompting them to turn to nationalist agendas, as in the U.S. election and Brexit referendum. “Therefore wait ye upon me, saith the LORD, until the day that I rise up to the prey: for my determination is to gather the nations, that I may assemble the kingdoms, to pour upon them mine indignation, even all my fierce anger: for all the earth shall be devoured with the fire of my jealousy.” Zephaniah 3:8 (KJV) EDITOR’S NOTE: The Bible clearly says that God’s desire is to “gather all the nations of the world together”, in order to “pour His fury” upon them. The United Nations, something unique in world history, has been created by the will of God, and things are going to end exactly how the Bible says they will end. All Muslims will be driven out of Israel as prophesied in Zechariah 14:21 (KJV), Israel will expand its borders to cover the size of the original land grant to Abraham , and Jesus will rule the world from Jerusalem . And that will be the “new” world order. Antonio Guterres, elected in October to take over as U.N. secretary general next year , told a conference in his native Lisbon that this trend had undermined the willingness to receive refugees in Europe this year. He said the world must re-establish international protection for refugees coming from war zones such as Syria, but it would not be easy as developed countries were turning to nationalist agendas. Antonio Guterres formally elected as UN chief: Europe has struggled to handle a huge influx of refugees, many of whom displaced by the war in Syria. The United States has accepted only a very small number of refugees and may take in even fewer next year. “In 2016, we have witnessed a dramatic deterioration of that international protection regime (for refugees),” Guterres said. “This example started in the developed world, it started essentially in Europe, it is spreading now like a virus into other parts of the world.” Guterres, who was U.N. High Commissioner for Refugees until last year, linked the growing resistance to accepting refugees to wider concerns about globalism. “I don’t think we can look strictly at the refugee issue, I think the problem is a broader problem,” he told the conference on Europe’s refugee crisis. There was a consensus in the mid-1990s that globalization would benefit all, he said. “But a lot of people were left behind … In the developed world, (there are) those who have been losers in globalization,” he said. “The recent analysis of the rust belt in the United States, I think, is a clear demonstration of that, when we speak about the elections.” Donald Trump won this month’s election in the United States in part thanks to support from voters who have seen their jobs lost to countries with cheaper labor. “So globalization has not been as successful as we had hoped and lots of people became not only angry with it, but feeling that political establishments and international organizations are not paying attention, were not taking care (of them),” he said. This led to what he called “a kind of evolution” in which anti-establishment parties now tended to win elections and referendums tended to attract majorities against whatever was put to a vote. source SHARE THIS ARTICLE  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773.6980395934685"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_article_length = 0\n",
    "\n",
    "for i in range(20761):\n",
    "    if i in nan_indexes:\n",
    "        continue\n",
    "    mean_article_length += len(X[i].split(' '))\n",
    "\n",
    "mean_article_length /= 20761\n",
    "\n",
    "mean_article_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 3000\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,75,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(96)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras as K\n",
    "\n",
    "def train_model(model_id, model, optimizer, epochs, X_train, y_train, validation_split, batch_size):\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('NNs/model-{epoch:03d}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tb_callback = K.callbacks.TensorBoard(log_dir='./logs/nn_' + str(model_id))\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[tb_callback, checkpoint])\n",
    "    \n",
    "    return hist\n",
    "\n",
    "#hist = train_model(...)\n",
    "#best_epoch = max(hist.history['val_loss'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 1000, 75)          225000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 96)                66432     \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 97        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 291,529\n",
      "Trainable params: 291,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/30\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.4087 - acc: 0.8227 - val_loss: 0.2360 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23604, saving model to NNs/model-001.h5\n",
      "Epoch 2/30\n",
      "16608/16608 [==============================] - 7s 442us/step - loss: 0.2229 - acc: 0.9152 - val_loss: 0.2013 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23604 to 0.20131, saving model to NNs/model-002.h5\n",
      "Epoch 3/30\n",
      "16608/16608 [==============================] - 7s 452us/step - loss: 0.1656 - acc: 0.9441 - val_loss: 0.2464 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20131\n",
      "Epoch 4/30\n",
      "16608/16608 [==============================] - 7s 450us/step - loss: 0.1730 - acc: 0.9415 - val_loss: 0.2032 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20131\n",
      "Epoch 5/30\n",
      "16608/16608 [==============================] - 8s 459us/step - loss: 0.1430 - acc: 0.9530 - val_loss: 0.1943 - val_acc: 0.9335\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20131 to 0.19435, saving model to NNs/model-005.h5\n",
      "Epoch 6/30\n",
      "16608/16608 [==============================] - 8s 462us/step - loss: 0.1270 - acc: 0.9577 - val_loss: 0.1998 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.19435\n",
      "Epoch 7/30\n",
      "16608/16608 [==============================] - 8s 459us/step - loss: 0.1645 - acc: 0.9348 - val_loss: 0.2018 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19435\n",
      "Epoch 8/30\n",
      "16608/16608 [==============================] - 8s 460us/step - loss: 0.1288 - acc: 0.9588 - val_loss: 0.1942 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19435 to 0.19422, saving model to NNs/model-008.h5\n",
      "Epoch 9/30\n",
      "16608/16608 [==============================] - 7s 450us/step - loss: 0.0894 - acc: 0.9717 - val_loss: 0.1886 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19422 to 0.18857, saving model to NNs/model-009.h5\n",
      "Epoch 10/30\n",
      "16608/16608 [==============================] - 8s 452us/step - loss: 0.1463 - acc: 0.9466 - val_loss: 0.2254 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18857\n",
      "Epoch 11/30\n",
      "16608/16608 [==============================] - 8s 453us/step - loss: 0.1068 - acc: 0.9622 - val_loss: 0.2077 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18857\n",
      "Epoch 12/30\n",
      "16608/16608 [==============================] - 8s 462us/step - loss: 0.1469 - acc: 0.9520 - val_loss: 0.2184 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18857\n",
      "Epoch 13/30\n",
      "16608/16608 [==============================] - 8s 460us/step - loss: 0.2222 - acc: 0.9131 - val_loss: 0.1962 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18857\n",
      "Epoch 14/30\n",
      "16608/16608 [==============================] - 7s 444us/step - loss: 0.1066 - acc: 0.9641 - val_loss: 0.2325 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18857\n",
      "Epoch 15/30\n",
      "16608/16608 [==============================] - 7s 446us/step - loss: 0.1008 - acc: 0.9670 - val_loss: 0.2324 - val_acc: 0.9292\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18857\n",
      "Epoch 16/30\n",
      " 4608/16608 [=======>......................] - ETA: 5s - loss: 0.0759 - acc: 0.9748"
     ]
    }
   ],
   "source": [
    "model = LSTM_network()\n",
    "\n",
    "train_model('LSTM 1 layer 75 words', model, Adam(), 30, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(sequences_matrix,y,batch_size=128,epochs=20,\n",
    "          validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = SimpleRNN(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1000, 50)          100000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 64)                7360      \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 124,257\n",
      "Trainable params: 124,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.6715 - acc: 0.5984 - val_loss: 0.6128 - val_acc: 0.7250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61277, saving model to NNs/model-001.h5\n",
      "Epoch 2/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5661 - acc: 0.7249 - val_loss: 0.5287 - val_acc: 0.7450\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61277 to 0.52872, saving model to NNs/model-002.h5\n",
      "Epoch 3/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4943 - acc: 0.7620 - val_loss: 0.4776 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.52872 to 0.47757, saving model to NNs/model-003.h5\n",
      "Epoch 4/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.6548 - acc: 0.6172 - val_loss: 0.6088 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47757\n",
      "Epoch 5/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5700 - acc: 0.7149 - val_loss: 0.5276 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47757\n",
      "Epoch 6/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5377 - acc: 0.7346 - val_loss: 0.5032 - val_acc: 0.7595\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47757\n",
      "Epoch 7/30\n",
      "16608/16608 [==============================] - 22s 1ms/step - loss: 0.5023 - acc: 0.7542 - val_loss: 0.4807 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47757\n",
      "Epoch 8/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4626 - acc: 0.7793 - val_loss: 0.4152 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47757 to 0.41524, saving model to NNs/model-008.h5\n",
      "Epoch 9/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5131 - acc: 0.7633 - val_loss: 0.5042 - val_acc: 0.7712\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41524\n",
      "Epoch 10/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5072 - acc: 0.7641 - val_loss: 0.4990 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41524\n",
      "Epoch 11/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4982 - acc: 0.7704 - val_loss: 0.4979 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.41524\n",
      "Epoch 12/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4931 - acc: 0.7747 - val_loss: 0.5319 - val_acc: 0.7173\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.41524\n",
      "Epoch 13/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4885 - acc: 0.7758 - val_loss: 0.5027 - val_acc: 0.7409\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.41524\n",
      "Epoch 14/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4845 - acc: 0.7819 - val_loss: 0.5094 - val_acc: 0.7339\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.41524\n",
      "Epoch 15/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4770 - acc: 0.7841 - val_loss: 0.4886 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.41524\n",
      "Epoch 16/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4684 - acc: 0.7863 - val_loss: 0.4821 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.41524\n",
      "Epoch 17/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4655 - acc: 0.7865 - val_loss: 0.5213 - val_acc: 0.7171\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.41524\n",
      "Epoch 18/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4609 - acc: 0.7879 - val_loss: 0.4973 - val_acc: 0.7705\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.41524\n",
      "Epoch 19/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4619 - acc: 0.7873 - val_loss: 0.4814 - val_acc: 0.7643\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.41524\n",
      "Epoch 20/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4541 - acc: 0.7918 - val_loss: 0.4861 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.41524\n",
      "Epoch 21/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4546 - acc: 0.7895 - val_loss: 0.5261 - val_acc: 0.7696\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.41524\n",
      "Epoch 22/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4499 - acc: 0.7916 - val_loss: 0.4945 - val_acc: 0.7310\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.41524\n",
      "Epoch 23/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4486 - acc: 0.7924 - val_loss: 0.4769 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.41524\n",
      "Epoch 24/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4465 - acc: 0.7920 - val_loss: 0.5017 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.41524\n",
      "Epoch 25/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4470 - acc: 0.7905 - val_loss: 0.4795 - val_acc: 0.7676\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.41524\n",
      "Epoch 26/30\n",
      "16608/16608 [==============================] - 22s 1ms/step - loss: 0.4441 - acc: 0.7906 - val_loss: 0.4800 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.41524\n",
      "Epoch 27/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4446 - acc: 0.7946 - val_loss: 0.4797 - val_acc: 0.7681\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.41524\n",
      "Epoch 28/30\n",
      "16608/16608 [==============================] - 22s 1ms/step - loss: 0.4420 - acc: 0.7967 - val_loss: 0.4828 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.41524\n",
      "Epoch 29/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4375 - acc: 0.7965 - val_loss: 0.4868 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.41524\n",
      "Epoch 30/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4381 - acc: 0.7949 - val_loss: 0.4897 - val_acc: 0.7681\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.41524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f897c0a7828>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN_network()\n",
    "\n",
    "train_model('rnn', model, SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True), 30, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = GRU(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 1000, 50)          100000    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                22080     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 138,977\n",
      "Trainable params: 138,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.3890 - acc: 0.8350 - val_loss: 0.2549 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25488, saving model to NNs/model-001.h5\n",
      "Epoch 2/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1728 - acc: 0.9379 - val_loss: 0.1813 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25488 to 0.18128, saving model to NNs/model-002.h5\n",
      "Epoch 3/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.1556 - acc: 0.9465 - val_loss: 0.1867 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18128\n",
      "Epoch 4/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.1629 - acc: 0.9424 - val_loss: 0.1734 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18128 to 0.17341, saving model to NNs/model-004.h5\n",
      "Epoch 5/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.1181 - acc: 0.9607 - val_loss: 0.1818 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17341\n",
      "Epoch 6/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.0932 - acc: 0.9686 - val_loss: 0.1629 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17341 to 0.16289, saving model to NNs/model-006.h5\n",
      "Epoch 7/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0782 - acc: 0.9733 - val_loss: 0.2109 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16289\n",
      "Epoch 8/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0721 - acc: 0.9765 - val_loss: 0.1747 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16289\n",
      "Epoch 9/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.0509 - acc: 0.9849 - val_loss: 0.1943 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16289\n",
      "Epoch 10/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0417 - acc: 0.9871 - val_loss: 0.1927 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16289\n",
      "Epoch 11/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0391 - acc: 0.9875 - val_loss: 0.2524 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16289\n",
      "Epoch 12/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0381 - acc: 0.9879 - val_loss: 0.2215 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16289\n",
      "Epoch 13/30\n",
      "16608/16608 [==============================] - 58s 3ms/step - loss: 0.0290 - acc: 0.9910 - val_loss: 0.2020 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16289\n",
      "Epoch 14/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0486 - acc: 0.9860 - val_loss: 0.2250 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16289\n",
      "Epoch 15/30\n",
      "16608/16608 [==============================] - 63s 4ms/step - loss: 0.0295 - acc: 0.9910 - val_loss: 0.1985 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16289\n",
      "Epoch 16/30\n",
      "16608/16608 [==============================] - 58s 3ms/step - loss: 0.0225 - acc: 0.9940 - val_loss: 0.2138 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16289\n",
      "Epoch 17/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0199 - acc: 0.9942 - val_loss: 0.2675 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16289\n",
      "Epoch 18/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0382 - acc: 0.9890 - val_loss: 0.2162 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16289\n",
      "Epoch 19/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0213 - acc: 0.9934 - val_loss: 0.2418 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16289\n",
      "Epoch 20/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0194 - acc: 0.9945 - val_loss: 0.2244 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16289\n",
      "Epoch 21/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0244 - acc: 0.9911 - val_loss: 0.2352 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16289\n",
      "Epoch 22/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0335 - acc: 0.9896 - val_loss: 0.2053 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16289\n",
      "Epoch 23/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.2341 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16289\n",
      "Epoch 24/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0196 - acc: 0.9945 - val_loss: 0.2250 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16289\n",
      "Epoch 25/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.2645 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16289\n",
      "Epoch 26/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0305 - acc: 0.9918 - val_loss: 0.2321 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16289\n",
      "Epoch 27/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.2436 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16289\n",
      "Epoch 28/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.2778 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16289\n",
      "Epoch 29/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.2883 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16289\n",
      "Epoch 30/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.3122 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.16289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb6f0164ac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GRU_network()\n",
    "\n",
    "train_model('GRU', model, Adam(), 30, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM2_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(78)(layer)\n",
    "    layer = Dense(128,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1000, 50)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 78)                40248     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               10112     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 150,489\n",
      "Trainable params: 150,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 69s 4ms/step - loss: 0.3319 - acc: 0.8668 - val_loss: 0.1602 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16024, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.2313 - acc: 0.9065 - val_loss: 0.1677 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16024\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.2206 - acc: 0.9160 - val_loss: 0.3313 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16024\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 68s 4ms/step - loss: 0.1824 - acc: 0.9382 - val_loss: 0.1713 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16024\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 76s 5ms/step - loss: 0.1208 - acc: 0.9594 - val_loss: 0.1833 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16024\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 86s 5ms/step - loss: 0.1163 - acc: 0.9633 - val_loss: 0.1718 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16024\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 78s 5ms/step - loss: 0.1411 - acc: 0.9507 - val_loss: 0.1836 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16024\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 69s 4ms/step - loss: 0.1109 - acc: 0.9663 - val_loss: 0.2189 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16024\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 72s 4ms/step - loss: 0.1081 - acc: 0.9654 - val_loss: 0.1873 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16024\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 73s 4ms/step - loss: 0.0896 - acc: 0.9715 - val_loss: 0.1780 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16024\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 68s 4ms/step - loss: 0.1059 - acc: 0.9657 - val_loss: 0.1969 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16024\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.1197 - acc: 0.9619 - val_loss: 0.2262 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16024\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.0862 - acc: 0.9727 - val_loss: 0.1751 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16024\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.1192 - acc: 0.9632 - val_loss: 0.2543 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16024\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.1609 - acc: 0.9395 - val_loss: 0.3346 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb690fb8710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM2_network()\n",
    "\n",
    "train_model('LSTM2', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1500\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM3_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 1000, 50)          75000     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 121,337\n",
      "Trainable params: 121,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.3757 - acc: 0.8412 - val_loss: 0.1839 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18388, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.2130 - acc: 0.9152 - val_loss: 0.4035 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18388\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.2236 - acc: 0.9183 - val_loss: 0.2165 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18388\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1399 - acc: 0.9532 - val_loss: 0.1637 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18388 to 0.16374, saving model to NNs/model-004.h5\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1220 - acc: 0.9621 - val_loss: 0.1498 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16374 to 0.14979, saving model to NNs/model-005.h5\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1059 - acc: 0.9665 - val_loss: 0.1502 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14979\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0930 - acc: 0.9701 - val_loss: 0.1546 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14979\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0908 - acc: 0.9709 - val_loss: 0.1410 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14979 to 0.14096, saving model to NNs/model-008.h5\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1096 - acc: 0.9622 - val_loss: 0.2029 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14096\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0865 - acc: 0.9720 - val_loss: 0.1375 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.14096 to 0.13754, saving model to NNs/model-010.h5\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0571 - acc: 0.9825 - val_loss: 0.1595 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.13754\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1019 - acc: 0.9621 - val_loss: 0.1805 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.13754\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1370 - acc: 0.9494 - val_loss: 0.1841 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.13754\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1349 - acc: 0.9530 - val_loss: 0.2006 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.13754\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.2295 - acc: 0.9105 - val_loss: 0.4277 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.13754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb716638518>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM3_network()\n",
    "\n",
    "train_model('LSTM3', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM4_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,25,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 1000, 25)          37500     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                23040     \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 60,605\n",
      "Trainable params: 60,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.4125 - acc: 0.8257 - val_loss: 0.2726 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27264, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.2625 - acc: 0.8964 - val_loss: 0.2158 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27264 to 0.21579, saving model to NNs/model-002.h5\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.1828 - acc: 0.9352 - val_loss: 0.1885 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21579 to 0.18849, saving model to NNs/model-003.h5\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.2230 - acc: 0.9268 - val_loss: 0.2597 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18849\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 59s 4ms/step - loss: 0.2005 - acc: 0.9261 - val_loss: 0.2137 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18849\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 65s 4ms/step - loss: 0.1802 - acc: 0.9354 - val_loss: 0.1927 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18849\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 63s 4ms/step - loss: 0.1514 - acc: 0.9485 - val_loss: 0.1766 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.18849 to 0.17663, saving model to NNs/model-007.h5\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 64s 4ms/step - loss: 0.2918 - acc: 0.8810 - val_loss: 0.2079 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17663\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 58s 4ms/step - loss: 0.1602 - acc: 0.9458 - val_loss: 0.1942 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17663\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1640 - acc: 0.9443 - val_loss: 0.1954 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17663\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1475 - acc: 0.9500 - val_loss: 0.2078 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17663\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1615 - acc: 0.9431 - val_loss: 0.2436 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17663\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1419 - acc: 0.9527 - val_loss: 0.1947 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17663\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1270 - acc: 0.9598 - val_loss: 0.1920 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17663\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1291 - acc: 0.9586 - val_loss: 0.2225 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb714eb2e48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM4_network()\n",
    "\n",
    "train_model('LSTM4', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
