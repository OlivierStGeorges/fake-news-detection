{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import SimpleRNN, CuDNNLSTM, CuDNNGRU, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/train.csv')\n",
    "dataset.head()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_indexes = dataset.loc[pd.isna(dataset[\"text\"]), :].index\n",
    "dataset = dataset.drop(nan_indexes)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(142 in nan_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = dataset.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.text\n",
    "y = dataset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  U.N. Secretary General Complains That The ‘Masses Have Rejected Globalism’ In Favor Of Nationalism Antonio Guterres, elected in October to take over as U.N. secretary general next year, told a conference in his native Lisbon that this trend had undermined the willingness to receive refugees in Europe this year. He said the world must re-establish international protection for refugees coming from war zones such as Syria, but it would not be easy as developed countries were turning to nationalist agendas.   22, 2016 The incoming head of the United Nations warned on Tuesday that ‘losers of globalization’ in rich countries have felt ignored by establishment politicians, prompting them to turn to nationalist agendas, as in the U.S. election and Brexit referendum. “Therefore wait ye upon me, saith the LORD, until the day that I rise up to the prey: for my determination is to gather the nations, that I may assemble the kingdoms, to pour upon them mine indignation, even all my fierce anger: for all the earth shall be devoured with the fire of my jealousy.” Zephaniah 3:8 (KJV) EDITOR’S NOTE: The Bible clearly says that God’s desire is to “gather all the nations of the world together”, in order to “pour His fury” upon them. The United Nations, something unique in world history, has been created by the will of God, and things are going to end exactly how the Bible says they will end. All Muslims will be driven out of Israel as prophesied in Zechariah 14:21 (KJV), Israel will expand its borders to cover the size of the original land grant to Abraham , and Jesus will rule the world from Jerusalem . And that will be the “new” world order. Antonio Guterres, elected in October to take over as U.N. secretary general next year , told a conference in his native Lisbon that this trend had undermined the willingness to receive refugees in Europe this year. He said the world must re-establish international protection for refugees coming from war zones such as Syria, but it would not be easy as developed countries were turning to nationalist agendas. Antonio Guterres formally elected as UN chief: Europe has struggled to handle a huge influx of refugees, many of whom displaced by the war in Syria. The United States has accepted only a very small number of refugees and may take in even fewer next year. “In 2016, we have witnessed a dramatic deterioration of that international protection regime (for refugees),” Guterres said. “This example started in the developed world, it started essentially in Europe, it is spreading now like a virus into other parts of the world.” Guterres, who was U.N. High Commissioner for Refugees until last year, linked the growing resistance to accepting refugees to wider concerns about globalism. “I don’t think we can look strictly at the refugee issue, I think the problem is a broader problem,” he told the conference on Europe’s refugee crisis. There was a consensus in the mid-1990s that globalization would benefit all, he said. “But a lot of people were left behind … In the developed world, (there are) those who have been losers in globalization,” he said. “The recent analysis of the rust belt in the United States, I think, is a clear demonstration of that, when we speak about the elections.” Donald Trump won this month’s election in the United States in part thanks to support from voters who have seen their jobs lost to countries with cheaper labor. “So globalization has not been as successful as we had hoped and lots of people became not only angry with it, but feeling that political establishments and international organizations are not paying attention, were not taking care (of them),” he said. This led to what he called “a kind of evolution” in which anti-establishment parties now tended to win elections and referendums tended to attract majorities against whatever was put to a vote. source SHARE THIS ARTICLE  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773.6980395934685"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_article_length = 0\n",
    "\n",
    "for i in range(20761):\n",
    "    if i in nan_indexes:\n",
    "        continue\n",
    "    mean_article_length += len(X[i].split(' '))\n",
    "\n",
    "mean_article_length /= 20761\n",
    "\n",
    "mean_article_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 3000\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,75,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(96)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras as K\n",
    "\n",
    "def train_model(model_id, model, optimizer, epochs, X_train, y_train, validation_split, batch_size):\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('NNs/' + model_id + '-{epoch:03d}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tb_callback = K.callbacks.TensorBoard(log_dir='./logs/nn_' + str(model_id))\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[tb_callback, checkpoint])\n",
    "    \n",
    "    return hist\n",
    "\n",
    "#hist = train_model(...)\n",
    "#best_epoch = max(hist.history['val_loss'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 1000, 75)          225000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 96)                66432     \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 97        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 291,529\n",
      "Trainable params: 291,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/30\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.4087 - acc: 0.8227 - val_loss: 0.2360 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23604, saving model to NNs/model-001.h5\n",
      "Epoch 2/30\n",
      "16608/16608 [==============================] - 7s 442us/step - loss: 0.2229 - acc: 0.9152 - val_loss: 0.2013 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23604 to 0.20131, saving model to NNs/model-002.h5\n",
      "Epoch 3/30\n",
      "16608/16608 [==============================] - 7s 452us/step - loss: 0.1656 - acc: 0.9441 - val_loss: 0.2464 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20131\n",
      "Epoch 4/30\n",
      "16608/16608 [==============================] - 7s 450us/step - loss: 0.1730 - acc: 0.9415 - val_loss: 0.2032 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20131\n",
      "Epoch 5/30\n",
      "16608/16608 [==============================] - 8s 459us/step - loss: 0.1430 - acc: 0.9530 - val_loss: 0.1943 - val_acc: 0.9335\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20131 to 0.19435, saving model to NNs/model-005.h5\n",
      "Epoch 6/30\n",
      "16608/16608 [==============================] - 8s 462us/step - loss: 0.1270 - acc: 0.9577 - val_loss: 0.1998 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.19435\n",
      "Epoch 7/30\n",
      "16608/16608 [==============================] - 8s 459us/step - loss: 0.1645 - acc: 0.9348 - val_loss: 0.2018 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19435\n",
      "Epoch 8/30\n",
      "16608/16608 [==============================] - 8s 460us/step - loss: 0.1288 - acc: 0.9588 - val_loss: 0.1942 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19435 to 0.19422, saving model to NNs/model-008.h5\n",
      "Epoch 9/30\n",
      "16608/16608 [==============================] - 7s 450us/step - loss: 0.0894 - acc: 0.9717 - val_loss: 0.1886 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19422 to 0.18857, saving model to NNs/model-009.h5\n",
      "Epoch 10/30\n",
      "16608/16608 [==============================] - 8s 452us/step - loss: 0.1463 - acc: 0.9466 - val_loss: 0.2254 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18857\n",
      "Epoch 11/30\n",
      "16608/16608 [==============================] - 8s 453us/step - loss: 0.1068 - acc: 0.9622 - val_loss: 0.2077 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18857\n",
      "Epoch 12/30\n",
      "16608/16608 [==============================] - 8s 462us/step - loss: 0.1469 - acc: 0.9520 - val_loss: 0.2184 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18857\n",
      "Epoch 13/30\n",
      "16608/16608 [==============================] - 8s 460us/step - loss: 0.2222 - acc: 0.9131 - val_loss: 0.1962 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18857\n",
      "Epoch 14/30\n",
      "16608/16608 [==============================] - 7s 444us/step - loss: 0.1066 - acc: 0.9641 - val_loss: 0.2325 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18857\n",
      "Epoch 15/30\n",
      "16608/16608 [==============================] - 7s 446us/step - loss: 0.1008 - acc: 0.9670 - val_loss: 0.2324 - val_acc: 0.9292\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18857\n",
      "Epoch 16/30\n",
      " 4608/16608 [=======>......................] - ETA: 5s - loss: 0.0759 - acc: 0.9748"
     ]
    }
   ],
   "source": [
    "model = LSTM_network()\n",
    "\n",
    "train_model('LSTM 1 layer 75 words', model, Adam(), 30, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(sequences_matrix,y,batch_size=128,epochs=20,\n",
    "          validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = SimpleRNN(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1000, 50)          100000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 64)                7360      \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 124,257\n",
      "Trainable params: 124,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.6715 - acc: 0.5984 - val_loss: 0.6128 - val_acc: 0.7250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61277, saving model to NNs/model-001.h5\n",
      "Epoch 2/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5661 - acc: 0.7249 - val_loss: 0.5287 - val_acc: 0.7450\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61277 to 0.52872, saving model to NNs/model-002.h5\n",
      "Epoch 3/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4943 - acc: 0.7620 - val_loss: 0.4776 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.52872 to 0.47757, saving model to NNs/model-003.h5\n",
      "Epoch 4/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.6548 - acc: 0.6172 - val_loss: 0.6088 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47757\n",
      "Epoch 5/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5700 - acc: 0.7149 - val_loss: 0.5276 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47757\n",
      "Epoch 6/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5377 - acc: 0.7346 - val_loss: 0.5032 - val_acc: 0.7595\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47757\n",
      "Epoch 7/30\n",
      "16608/16608 [==============================] - 22s 1ms/step - loss: 0.5023 - acc: 0.7542 - val_loss: 0.4807 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47757\n",
      "Epoch 8/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4626 - acc: 0.7793 - val_loss: 0.4152 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47757 to 0.41524, saving model to NNs/model-008.h5\n",
      "Epoch 9/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5131 - acc: 0.7633 - val_loss: 0.5042 - val_acc: 0.7712\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41524\n",
      "Epoch 10/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.5072 - acc: 0.7641 - val_loss: 0.4990 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41524\n",
      "Epoch 11/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4982 - acc: 0.7704 - val_loss: 0.4979 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.41524\n",
      "Epoch 12/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4931 - acc: 0.7747 - val_loss: 0.5319 - val_acc: 0.7173\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.41524\n",
      "Epoch 13/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4885 - acc: 0.7758 - val_loss: 0.5027 - val_acc: 0.7409\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.41524\n",
      "Epoch 14/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4845 - acc: 0.7819 - val_loss: 0.5094 - val_acc: 0.7339\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.41524\n",
      "Epoch 15/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4770 - acc: 0.7841 - val_loss: 0.4886 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.41524\n",
      "Epoch 16/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4684 - acc: 0.7863 - val_loss: 0.4821 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.41524\n",
      "Epoch 17/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4655 - acc: 0.7865 - val_loss: 0.5213 - val_acc: 0.7171\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.41524\n",
      "Epoch 18/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4609 - acc: 0.7879 - val_loss: 0.4973 - val_acc: 0.7705\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.41524\n",
      "Epoch 19/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4619 - acc: 0.7873 - val_loss: 0.4814 - val_acc: 0.7643\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.41524\n",
      "Epoch 20/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4541 - acc: 0.7918 - val_loss: 0.4861 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.41524\n",
      "Epoch 21/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4546 - acc: 0.7895 - val_loss: 0.5261 - val_acc: 0.7696\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.41524\n",
      "Epoch 22/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4499 - acc: 0.7916 - val_loss: 0.4945 - val_acc: 0.7310\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.41524\n",
      "Epoch 23/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4486 - acc: 0.7924 - val_loss: 0.4769 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.41524\n",
      "Epoch 24/30\n",
      "16608/16608 [==============================] - 20s 1ms/step - loss: 0.4465 - acc: 0.7920 - val_loss: 0.5017 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.41524\n",
      "Epoch 25/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4470 - acc: 0.7905 - val_loss: 0.4795 - val_acc: 0.7676\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.41524\n",
      "Epoch 26/30\n",
      "16608/16608 [==============================] - 22s 1ms/step - loss: 0.4441 - acc: 0.7906 - val_loss: 0.4800 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.41524\n",
      "Epoch 27/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4446 - acc: 0.7946 - val_loss: 0.4797 - val_acc: 0.7681\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.41524\n",
      "Epoch 28/30\n",
      "16608/16608 [==============================] - 22s 1ms/step - loss: 0.4420 - acc: 0.7967 - val_loss: 0.4828 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.41524\n",
      "Epoch 29/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4375 - acc: 0.7965 - val_loss: 0.4868 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.41524\n",
      "Epoch 30/30\n",
      "16608/16608 [==============================] - 21s 1ms/step - loss: 0.4381 - acc: 0.7949 - val_loss: 0.4897 - val_acc: 0.7681\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.41524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f897c0a7828>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN_network()\n",
    "\n",
    "train_model('rnn', model, SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True), 30, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = GRU(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 1000, 50)          100000    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                22080     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 138,977\n",
      "Trainable params: 138,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.3890 - acc: 0.8350 - val_loss: 0.2549 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25488, saving model to NNs/model-001.h5\n",
      "Epoch 2/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1728 - acc: 0.9379 - val_loss: 0.1813 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25488 to 0.18128, saving model to NNs/model-002.h5\n",
      "Epoch 3/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.1556 - acc: 0.9465 - val_loss: 0.1867 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18128\n",
      "Epoch 4/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.1629 - acc: 0.9424 - val_loss: 0.1734 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18128 to 0.17341, saving model to NNs/model-004.h5\n",
      "Epoch 5/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.1181 - acc: 0.9607 - val_loss: 0.1818 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17341\n",
      "Epoch 6/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.0932 - acc: 0.9686 - val_loss: 0.1629 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17341 to 0.16289, saving model to NNs/model-006.h5\n",
      "Epoch 7/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0782 - acc: 0.9733 - val_loss: 0.2109 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16289\n",
      "Epoch 8/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0721 - acc: 0.9765 - val_loss: 0.1747 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16289\n",
      "Epoch 9/30\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.0509 - acc: 0.9849 - val_loss: 0.1943 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16289\n",
      "Epoch 10/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0417 - acc: 0.9871 - val_loss: 0.1927 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16289\n",
      "Epoch 11/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0391 - acc: 0.9875 - val_loss: 0.2524 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16289\n",
      "Epoch 12/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0381 - acc: 0.9879 - val_loss: 0.2215 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16289\n",
      "Epoch 13/30\n",
      "16608/16608 [==============================] - 58s 3ms/step - loss: 0.0290 - acc: 0.9910 - val_loss: 0.2020 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16289\n",
      "Epoch 14/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0486 - acc: 0.9860 - val_loss: 0.2250 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16289\n",
      "Epoch 15/30\n",
      "16608/16608 [==============================] - 63s 4ms/step - loss: 0.0295 - acc: 0.9910 - val_loss: 0.1985 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16289\n",
      "Epoch 16/30\n",
      "16608/16608 [==============================] - 58s 3ms/step - loss: 0.0225 - acc: 0.9940 - val_loss: 0.2138 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16289\n",
      "Epoch 17/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0199 - acc: 0.9942 - val_loss: 0.2675 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16289\n",
      "Epoch 18/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0382 - acc: 0.9890 - val_loss: 0.2162 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16289\n",
      "Epoch 19/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0213 - acc: 0.9934 - val_loss: 0.2418 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16289\n",
      "Epoch 20/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0194 - acc: 0.9945 - val_loss: 0.2244 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16289\n",
      "Epoch 21/30\n",
      "16608/16608 [==============================] - 55s 3ms/step - loss: 0.0244 - acc: 0.9911 - val_loss: 0.2352 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16289\n",
      "Epoch 22/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0335 - acc: 0.9896 - val_loss: 0.2053 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16289\n",
      "Epoch 23/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.2341 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16289\n",
      "Epoch 24/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0196 - acc: 0.9945 - val_loss: 0.2250 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16289\n",
      "Epoch 25/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.2645 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16289\n",
      "Epoch 26/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0305 - acc: 0.9918 - val_loss: 0.2321 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16289\n",
      "Epoch 27/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.2436 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16289\n",
      "Epoch 28/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.2778 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16289\n",
      "Epoch 29/30\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.2883 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16289\n",
      "Epoch 30/30\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.3122 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.16289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb6f0164ac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GRU_network()\n",
    "\n",
    "train_model('GRU', model, Adam(), 30, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM2_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(78)(layer)\n",
    "    layer = Dense(128,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1000, 50)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 78)                40248     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               10112     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 150,489\n",
      "Trainable params: 150,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 69s 4ms/step - loss: 0.3319 - acc: 0.8668 - val_loss: 0.1602 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16024, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.2313 - acc: 0.9065 - val_loss: 0.1677 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16024\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.2206 - acc: 0.9160 - val_loss: 0.3313 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16024\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 68s 4ms/step - loss: 0.1824 - acc: 0.9382 - val_loss: 0.1713 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16024\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 76s 5ms/step - loss: 0.1208 - acc: 0.9594 - val_loss: 0.1833 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16024\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 86s 5ms/step - loss: 0.1163 - acc: 0.9633 - val_loss: 0.1718 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16024\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 78s 5ms/step - loss: 0.1411 - acc: 0.9507 - val_loss: 0.1836 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16024\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 69s 4ms/step - loss: 0.1109 - acc: 0.9663 - val_loss: 0.2189 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16024\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 72s 4ms/step - loss: 0.1081 - acc: 0.9654 - val_loss: 0.1873 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16024\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 73s 4ms/step - loss: 0.0896 - acc: 0.9715 - val_loss: 0.1780 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16024\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 68s 4ms/step - loss: 0.1059 - acc: 0.9657 - val_loss: 0.1969 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16024\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.1197 - acc: 0.9619 - val_loss: 0.2262 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16024\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.0862 - acc: 0.9727 - val_loss: 0.1751 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16024\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.1192 - acc: 0.9632 - val_loss: 0.2543 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16024\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 67s 4ms/step - loss: 0.1609 - acc: 0.9395 - val_loss: 0.3346 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb690fb8710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM2_network()\n",
    "\n",
    "train_model('LSTM2', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1500\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM3_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 1000, 50)          75000     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 121,337\n",
      "Trainable params: 121,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.3757 - acc: 0.8412 - val_loss: 0.1839 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18388, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.2130 - acc: 0.9152 - val_loss: 0.4035 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18388\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.2236 - acc: 0.9183 - val_loss: 0.2165 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18388\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1399 - acc: 0.9532 - val_loss: 0.1637 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18388 to 0.16374, saving model to NNs/model-004.h5\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1220 - acc: 0.9621 - val_loss: 0.1498 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16374 to 0.14979, saving model to NNs/model-005.h5\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1059 - acc: 0.9665 - val_loss: 0.1502 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14979\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0930 - acc: 0.9701 - val_loss: 0.1546 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14979\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.0908 - acc: 0.9709 - val_loss: 0.1410 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14979 to 0.14096, saving model to NNs/model-008.h5\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1096 - acc: 0.9622 - val_loss: 0.2029 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14096\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0865 - acc: 0.9720 - val_loss: 0.1375 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.14096 to 0.13754, saving model to NNs/model-010.h5\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.0571 - acc: 0.9825 - val_loss: 0.1595 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.13754\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1019 - acc: 0.9621 - val_loss: 0.1805 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.13754\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1370 - acc: 0.9494 - val_loss: 0.1841 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.13754\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1349 - acc: 0.9530 - val_loss: 0.2006 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.13754\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.2295 - acc: 0.9105 - val_loss: 0.4277 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.13754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb716638518>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM3_network()\n",
    "\n",
    "train_model('LSTM3', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM4_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,25,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 1000, 25)          37500     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                23040     \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 60,605\n",
      "Trainable params: 60,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.4125 - acc: 0.8257 - val_loss: 0.2726 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27264, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.2625 - acc: 0.8964 - val_loss: 0.2158 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27264 to 0.21579, saving model to NNs/model-002.h5\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 52s 3ms/step - loss: 0.1828 - acc: 0.9352 - val_loss: 0.1885 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21579 to 0.18849, saving model to NNs/model-003.h5\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.2230 - acc: 0.9268 - val_loss: 0.2597 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18849\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 59s 4ms/step - loss: 0.2005 - acc: 0.9261 - val_loss: 0.2137 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18849\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 65s 4ms/step - loss: 0.1802 - acc: 0.9354 - val_loss: 0.1927 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18849\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 63s 4ms/step - loss: 0.1514 - acc: 0.9485 - val_loss: 0.1766 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.18849 to 0.17663, saving model to NNs/model-007.h5\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 64s 4ms/step - loss: 0.2918 - acc: 0.8810 - val_loss: 0.2079 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17663\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 58s 4ms/step - loss: 0.1602 - acc: 0.9458 - val_loss: 0.1942 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17663\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1640 - acc: 0.9443 - val_loss: 0.1954 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17663\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1475 - acc: 0.9500 - val_loss: 0.2078 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17663\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 54s 3ms/step - loss: 0.1615 - acc: 0.9431 - val_loss: 0.2436 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17663\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1419 - acc: 0.9527 - val_loss: 0.1947 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17663\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1270 - acc: 0.9598 - val_loss: 0.1920 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17663\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 53s 3ms/step - loss: 0.1291 - acc: 0.9586 - val_loss: 0.2225 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb714eb2e48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM4_network()\n",
    "\n",
    "train_model('LSTM4', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM5_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 196,593\n",
      "Trainable params: 196,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 16s 987us/step - loss: 0.3417 - acc: 0.8530 - val_loss: 0.1777 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17769, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 8s 473us/step - loss: 0.1363 - acc: 0.9524 - val_loss: 0.1559 - val_acc: 0.9439\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17769 to 0.15592, saving model to NNs/model-002.h5\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 8s 455us/step - loss: 0.1861 - acc: 0.9252 - val_loss: 0.2269 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15592\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 7s 427us/step - loss: 0.1608 - acc: 0.9450 - val_loss: 0.2048 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15592\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 7s 449us/step - loss: 0.1361 - acc: 0.9537 - val_loss: 0.2305 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15592\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.1121 - acc: 0.9638 - val_loss: 0.1707 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15592\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 7s 444us/step - loss: 0.0922 - acc: 0.9712 - val_loss: 0.2095 - val_acc: 0.9258\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15592\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 7s 418us/step - loss: 0.1052 - acc: 0.9657 - val_loss: 0.2210 - val_acc: 0.9398\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15592\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 7s 445us/step - loss: 0.2097 - acc: 0.9111 - val_loss: 0.3604 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15592\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.1508 - acc: 0.9403 - val_loss: 0.2045 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15592\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 8s 471us/step - loss: 0.0707 - acc: 0.9770 - val_loss: 0.2333 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.15592\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 8s 472us/step - loss: 0.0638 - acc: 0.9801 - val_loss: 0.5882 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.15592\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.2053 - acc: 0.9093 - val_loss: 0.3762 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15592\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.1764 - acc: 0.9246 - val_loss: 0.2108 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.15592\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 8s 473us/step - loss: 0.0655 - acc: 0.9785 - val_loss: 0.2604 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.15592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff79edbbb38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM5_network()\n",
    "train_model('LSTM5', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM6_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words, 128, input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(128)(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 1000, 128)         384000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 516,225\n",
      "Trainable params: 516,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 13s 774us/step - loss: 0.3863 - acc: 0.8411 - val_loss: 0.2210 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22096, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 12s 749us/step - loss: 0.1948 - acc: 0.9315 - val_loss: 0.2244 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22096\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 12s 745us/step - loss: 0.1986 - acc: 0.9291 - val_loss: 0.3506 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22096\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 12s 742us/step - loss: 0.1656 - acc: 0.9442 - val_loss: 0.1943 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22096 to 0.19434, saving model to NNs/model-004.h5\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 12s 749us/step - loss: 0.1824 - acc: 0.9349 - val_loss: 0.1945 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19434\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 12s 743us/step - loss: 0.1279 - acc: 0.9559 - val_loss: 0.2041 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.19434\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 12s 748us/step - loss: 0.1542 - acc: 0.9450 - val_loss: 0.2230 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19434\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 12s 748us/step - loss: 0.1195 - acc: 0.9580 - val_loss: 0.3418 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19434\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 12s 747us/step - loss: 0.1102 - acc: 0.9622 - val_loss: 0.3449 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19434\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 12s 742us/step - loss: 0.1953 - acc: 0.9314 - val_loss: 0.2175 - val_acc: 0.9258\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19434\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 12s 748us/step - loss: 0.1443 - acc: 0.9510 - val_loss: 0.2689 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.19434\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 12s 748us/step - loss: 0.1673 - acc: 0.9359 - val_loss: 0.2457 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.19434\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 12s 747us/step - loss: 0.1531 - acc: 0.9451 - val_loss: 0.2267 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.19434\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 12s 749us/step - loss: 0.0875 - acc: 0.9696 - val_loss: 0.2292 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.19434\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 12s 751us/step - loss: 0.1732 - acc: 0.9303 - val_loss: 0.2311 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff79c2eb7f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM6_network()\n",
    "train_model('LSTM6', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM7_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words, 96, input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(96)(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 1000, 96)          288000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 96)                74496     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 97        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 362,593\n",
      "Trainable params: 362,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 10s 599us/step - loss: 0.4423 - acc: 0.7937 - val_loss: 0.4199 - val_acc: 0.7999\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41990, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 9s 570us/step - loss: 0.3035 - acc: 0.8755 - val_loss: 0.2583 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41990 to 0.25834, saving model to NNs/model-002.h5\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 10s 576us/step - loss: 0.3195 - acc: 0.8621 - val_loss: 0.4246 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25834\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 10s 577us/step - loss: 0.3237 - acc: 0.8567 - val_loss: 0.3440 - val_acc: 0.8401\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25834\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 10s 577us/step - loss: 0.2301 - acc: 0.9072 - val_loss: 0.2991 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25834\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 10s 578us/step - loss: 0.2380 - acc: 0.9026 - val_loss: 0.3898 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25834\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 10s 581us/step - loss: 0.2131 - acc: 0.9150 - val_loss: 0.2580 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25834 to 0.25797, saving model to NNs/model-007.h5\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 10s 579us/step - loss: 0.1363 - acc: 0.9526 - val_loss: 0.1943 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.25797 to 0.19431, saving model to NNs/model-008.h5\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 10s 576us/step - loss: 0.1303 - acc: 0.9542 - val_loss: 0.2414 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19431\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 9s 563us/step - loss: 0.1089 - acc: 0.9642 - val_loss: 0.1961 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19431\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 10s 574us/step - loss: 0.1236 - acc: 0.9577 - val_loss: 0.2243 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.19431\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 10s 577us/step - loss: 0.1113 - acc: 0.9628 - val_loss: 0.1995 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.19431\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 10s 581us/step - loss: 0.0865 - acc: 0.9723 - val_loss: 0.2010 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.19431\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 10s 577us/step - loss: 0.1818 - acc: 0.9255 - val_loss: 0.2844 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.19431\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 10s 579us/step - loss: 0.1107 - acc: 0.9616 - val_loss: 0.2035 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7943457b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM7_network()\n",
    "train_model('LSTM7', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM8_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words, 96, input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(96)(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(24)(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1000, 96)          288000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)     (None, 96)                74496     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                2328      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 25        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 364,849\n",
      "Trainable params: 364,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 10s 608us/step - loss: 0.2936 - acc: 0.8642 - val_loss: 0.1578 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15784, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 10s 581us/step - loss: 0.1728 - acc: 0.9383 - val_loss: 0.1773 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15784\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 10s 578us/step - loss: 0.1920 - acc: 0.9241 - val_loss: 0.3536 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15784\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 10s 577us/step - loss: 0.2080 - acc: 0.9182 - val_loss: 0.2170 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15784\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 10s 576us/step - loss: 0.2211 - acc: 0.9152 - val_loss: 0.2140 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15784\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 10s 578us/step - loss: 0.1486 - acc: 0.9441 - val_loss: 0.1794 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15784\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 10s 579us/step - loss: 0.1556 - acc: 0.9414 - val_loss: 0.2245 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15784\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 10s 580us/step - loss: 0.0861 - acc: 0.9724 - val_loss: 0.1743 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15784\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 10s 576us/step - loss: 0.1404 - acc: 0.9521 - val_loss: 0.2144 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15784\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 10s 577us/step - loss: 0.0907 - acc: 0.9697 - val_loss: 0.2581 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15784\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 10s 575us/step - loss: 0.1041 - acc: 0.9653 - val_loss: 0.1929 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.15784\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 10s 580us/step - loss: 0.0565 - acc: 0.9830 - val_loss: 0.2427 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.15784\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 10s 577us/step - loss: 0.0465 - acc: 0.9869 - val_loss: 0.2296 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15784\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 10s 574us/step - loss: 0.0328 - acc: 0.9916 - val_loss: 0.2562 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.15784\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 10s 580us/step - loss: 0.0226 - acc: 0.9938 - val_loss: 0.2448 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.15784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff77007ef98>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM8_network()\n",
    "train_model('LSTM8', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM9_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(64,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 183,921\n",
      "Trainable params: 183,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/15\n",
      "16608/16608 [==============================] - 8s 497us/step - loss: 0.3526 - acc: 0.8453 - val_loss: 0.1668 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16684, saving model to NNs/model-001.h5\n",
      "Epoch 2/15\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.2282 - acc: 0.9286 - val_loss: 0.1511 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16684 to 0.15106, saving model to NNs/model-002.h5\n",
      "Epoch 3/15\n",
      "16608/16608 [==============================] - 8s 480us/step - loss: 0.1397 - acc: 0.9539 - val_loss: 0.1755 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15106\n",
      "Epoch 4/15\n",
      "16608/16608 [==============================] - 8s 468us/step - loss: 0.2625 - acc: 0.8916 - val_loss: 0.3301 - val_acc: 0.8562\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15106\n",
      "Epoch 5/15\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.1791 - acc: 0.9335 - val_loss: 0.2052 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15106\n",
      "Epoch 6/15\n",
      "16608/16608 [==============================] - 8s 481us/step - loss: 0.2370 - acc: 0.9141 - val_loss: 0.2210 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15106\n",
      "Epoch 7/15\n",
      "16608/16608 [==============================] - 8s 479us/step - loss: 0.1285 - acc: 0.9567 - val_loss: 0.3735 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15106\n",
      "Epoch 8/15\n",
      "16608/16608 [==============================] - 7s 426us/step - loss: 0.2844 - acc: 0.8718 - val_loss: 0.2497 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15106\n",
      "Epoch 9/15\n",
      "16608/16608 [==============================] - 8s 455us/step - loss: 0.2174 - acc: 0.9108 - val_loss: 0.3257 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15106\n",
      "Epoch 10/15\n",
      "16608/16608 [==============================] - 8s 471us/step - loss: 0.1795 - acc: 0.9305 - val_loss: 0.2115 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15106\n",
      "Epoch 11/15\n",
      "16608/16608 [==============================] - 8s 470us/step - loss: 0.1325 - acc: 0.9545 - val_loss: 0.1965 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.15106\n",
      "Epoch 12/15\n",
      "16608/16608 [==============================] - 8s 462us/step - loss: 0.1133 - acc: 0.9638 - val_loss: 0.2225 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.15106\n",
      "Epoch 13/15\n",
      "16608/16608 [==============================] - 8s 463us/step - loss: 0.1019 - acc: 0.9675 - val_loss: 0.2043 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15106\n",
      "Epoch 14/15\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.0839 - acc: 0.9737 - val_loss: 0.2101 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.15106\n",
      "Epoch 15/15\n",
      "16608/16608 [==============================] - 8s 476us/step - loss: 0.0747 - acc: 0.9772 - val_loss: 0.1919 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.15106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff70c7eae48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM9_network()\n",
    "train_model('LSTM9', model, Adam(), 15, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM10_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(96)(layer)\n",
    "    layer = Dense(96,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_7 (CuDNNLSTM)     (None, 96)                56832     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 96)                9312      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 97        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 216,241\n",
      "Trainable params: 216,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 10s 590us/step - loss: 0.3847 - acc: 0.8142 - val_loss: 0.1657 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16565, saving model to NNs/model-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 560us/step - loss: 0.2560 - acc: 0.9008 - val_loss: 0.1956 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16565\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 558us/step - loss: 0.2193 - acc: 0.9152 - val_loss: 0.2857 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16565\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 9s 549us/step - loss: 0.1549 - acc: 0.9458 - val_loss: 0.2047 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16565\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 9s 559us/step - loss: 0.1237 - acc: 0.9585 - val_loss: 0.1858 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16565\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 9s 563us/step - loss: 0.1755 - acc: 0.9282 - val_loss: 0.2203 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16565\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 561us/step - loss: 0.1456 - acc: 0.9501 - val_loss: 0.6225 - val_acc: 0.6029\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16565\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 9s 563us/step - loss: 0.3032 - acc: 0.8709 - val_loss: 0.2606 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16565\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 9s 563us/step - loss: 0.2123 - acc: 0.9147 - val_loss: 0.2516 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16565\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 9s 564us/step - loss: 0.1865 - acc: 0.9249 - val_loss: 0.2446 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff52426bfd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM10_network()\n",
    "train_model('LSTM10', model, Adam(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM11_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(96)(layer)\n",
    "    layer = Dense(96,name='FC1',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_9 (CuDNNLSTM)     (None, 96)                56832     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 96)                9312      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 97        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 216,241\n",
      "Trainable params: 216,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 10s 598us/step - loss: 1.1928 - acc: 0.4970 - val_loss: 0.7957 - val_acc: 0.4927\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79573, saving model to NNs/model-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 553us/step - loss: 0.7352 - acc: 0.5022 - val_loss: 0.7120 - val_acc: 0.4927\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79573 to 0.71205, saving model to NNs/model-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 562us/step - loss: 0.7080 - acc: 0.5022 - val_loss: 0.7072 - val_acc: 0.4927\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.71205 to 0.70715, saving model to NNs/model-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 9s 551us/step - loss: 0.7057 - acc: 0.5022 - val_loss: 0.7063 - val_acc: 0.4927\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.70715 to 0.70625, saving model to NNs/model-004.h5\n",
      "Epoch 5/10\n",
      "14976/16608 [==========================>...] - ETA: 0s - loss: 0.7056 - acc: 0.5015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1a052f3c87ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM11_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-fb185385696d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_id, model, optimizer, epochs, X_train, y_train, validation_split, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtb_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./logs/nn_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LSTM11_network()\n",
    "train_model('LSTM11', model, Adam(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM12_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_10 (CuDNNLSTM)    (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 192,633\n",
      "Trainable params: 192,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 8s 510us/step - loss: 0.3420 - acc: 0.8533 - val_loss: 0.1540 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15401, saving model to NNs/model-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.1517 - acc: 0.9459 - val_loss: 0.1508 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15401 to 0.15082, saving model to NNs/model-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 7s 443us/step - loss: 0.1231 - acc: 0.9582 - val_loss: 0.1500 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15082 to 0.15003, saving model to NNs/model-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 7s 427us/step - loss: 0.1045 - acc: 0.9647 - val_loss: 0.2509 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15003\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 459us/step - loss: 0.1008 - acc: 0.9663 - val_loss: 0.2320 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15003\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 467us/step - loss: 0.1737 - acc: 0.9318 - val_loss: 0.2473 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15003\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.3762 - acc: 0.8378 - val_loss: 0.2622 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15003\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.2691 - acc: 0.8876 - val_loss: 0.2431 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15003\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 470us/step - loss: 0.2228 - acc: 0.9111 - val_loss: 0.3810 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15003\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 461us/step - loss: 0.1865 - acc: 0.9269 - val_loss: 0.2195 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4fb5dbe80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM12_network()\n",
    "train_model('LSTM12', model, Adam(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM13_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_12 (CuDNNLSTM)    (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 192,633\n",
      "Trainable params: 192,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 8s 501us/step - loss: 0.6907 - acc: 0.5535 - val_loss: 0.6901 - val_acc: 0.4927\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69008, saving model to NNs/model-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 458us/step - loss: 0.6839 - acc: 0.6465 - val_loss: 0.6760 - val_acc: 0.7378\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69008 to 0.67601, saving model to NNs/model-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 7s 432us/step - loss: 0.6524 - acc: 0.7080 - val_loss: 0.6004 - val_acc: 0.7614\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67601 to 0.60038, saving model to NNs/model-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 467us/step - loss: 0.5635 - acc: 0.7221 - val_loss: 0.4834 - val_acc: 0.7751\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.60038 to 0.48342, saving model to NNs/model-004.h5\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 472us/step - loss: 0.4972 - acc: 0.7637 - val_loss: 0.6149 - val_acc: 0.6424\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.48342\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.4621 - acc: 0.7856 - val_loss: 0.4156 - val_acc: 0.8131\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48342 to 0.41561, saving model to NNs/model-006.h5\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.4480 - acc: 0.7974 - val_loss: 0.4331 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41561\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 7s 441us/step - loss: 0.4176 - acc: 0.8130 - val_loss: 0.5495 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41561\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 7s 426us/step - loss: 0.4020 - acc: 0.8207 - val_loss: 0.3440 - val_acc: 0.8493\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.41561 to 0.34401, saving model to NNs/model-009.h5\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 467us/step - loss: 0.3918 - acc: 0.8257 - val_loss: 0.3619 - val_acc: 0.8478\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f9cedb38>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM14', model, SGD(lr=0.1), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_16 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_13 (CuDNNLSTM)    (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 192,633\n",
      "Trainable params: 192,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 8s 509us/step - loss: 0.3560 - acc: 0.8393 - val_loss: 0.2546 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25460, saving model to NNs/model-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 467us/step - loss: 0.1793 - acc: 0.9367 - val_loss: 0.1547 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25460 to 0.15471, saving model to NNs/model-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 462us/step - loss: 0.1523 - acc: 0.9482 - val_loss: 0.1545 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15471 to 0.15453, saving model to NNs/model-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 7s 421us/step - loss: 0.1378 - acc: 0.9557 - val_loss: 0.1787 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15453\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 458us/step - loss: 0.1288 - acc: 0.9609 - val_loss: 0.1355 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15453 to 0.13554, saving model to NNs/model-005.h5\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 477us/step - loss: 0.1039 - acc: 0.9659 - val_loss: 0.2149 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13554\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.0910 - acc: 0.9694 - val_loss: 0.2314 - val_acc: 0.9292\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13554\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 480us/step - loss: 0.0840 - acc: 0.9736 - val_loss: 0.1876 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13554\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 472us/step - loss: 0.0812 - acc: 0.9739 - val_loss: 0.1718 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13554\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 472us/step - loss: 0.0690 - acc: 0.9761 - val_loss: 0.1633 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f95fc048>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM15', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM16_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(60)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_17 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_14 (CuDNNLSTM)    (None, 60)                26880     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               11956     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 189,033\n",
      "Trainable params: 189,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 8s 502us/step - loss: 0.3861 - acc: 0.8360 - val_loss: 0.2508 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25076, saving model to NNs/LSTM16-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 7s 420us/step - loss: 0.2020 - acc: 0.9273 - val_loss: 0.1661 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25076 to 0.16606, saving model to NNs/LSTM16-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 7s 451us/step - loss: 0.1535 - acc: 0.9462 - val_loss: 0.5217 - val_acc: 0.8266\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16606\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 457us/step - loss: 0.1495 - acc: 0.9493 - val_loss: 0.1863 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16606\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 470us/step - loss: 0.1246 - acc: 0.9594 - val_loss: 0.1603 - val_acc: 0.9468\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16606 to 0.16032, saving model to NNs/LSTM16-005.h5\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 464us/step - loss: 0.1134 - acc: 0.9675 - val_loss: 0.2088 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16032\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 7s 443us/step - loss: 0.0891 - acc: 0.9710 - val_loss: 0.1415 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.16032 to 0.14150, saving model to NNs/LSTM16-007.h5\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 7s 422us/step - loss: 0.0717 - acc: 0.9767 - val_loss: 0.1544 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14150\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 463us/step - loss: 0.0725 - acc: 0.9774 - val_loss: 0.1524 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14150\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.0538 - acc: 0.9830 - val_loss: 0.1761 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f96fffd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM16_network()\n",
    "train_model('LSTM16', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM17_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(68)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_18 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_15 (CuDNNLSTM)    (None, 68)                32640     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               13524     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 196,361\n",
      "Trainable params: 196,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 550us/step - loss: 0.3480 - acc: 0.8551 - val_loss: 0.1832 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18315, saving model to NNs/LSTM17-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 508us/step - loss: 0.1921 - acc: 0.9334 - val_loss: 0.2178 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18315\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 489us/step - loss: 0.1540 - acc: 0.9462 - val_loss: 0.1928 - val_acc: 0.9285\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18315\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 487us/step - loss: 0.1306 - acc: 0.9555 - val_loss: 0.1417 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18315 to 0.14167, saving model to NNs/LSTM17-004.h5\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 508us/step - loss: 0.1197 - acc: 0.9603 - val_loss: 0.2143 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14167\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 507us/step - loss: 0.1018 - acc: 0.9672 - val_loss: 0.1579 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14167\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 512us/step - loss: 0.0920 - acc: 0.9704 - val_loss: 0.1482 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14167\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 509us/step - loss: 0.0828 - acc: 0.9757 - val_loss: 0.2026 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14167\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 508us/step - loss: 0.0654 - acc: 0.9789 - val_loss: 0.1700 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14167\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 505us/step - loss: 0.0623 - acc: 0.9789 - val_loss: 0.1871 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f87fb9b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM17_network()\n",
    "train_model('LSTM17', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM18_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(76)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_19 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_16 (CuDNNLSTM)    (None, 76)                38912     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               15092     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 204,201\n",
      "Trainable params: 204,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 558us/step - loss: 0.4120 - acc: 0.8346 - val_loss: 0.1961 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19609, saving model to NNs/LSTM18-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 520us/step - loss: 0.2033 - acc: 0.9260 - val_loss: 0.1986 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19609\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 519us/step - loss: 0.1580 - acc: 0.9438 - val_loss: 0.1879 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19609 to 0.18787, saving model to NNs/LSTM18-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 9s 519us/step - loss: 0.1372 - acc: 0.9529 - val_loss: 0.2023 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18787\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 499us/step - loss: 0.1184 - acc: 0.9606 - val_loss: 0.1498 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18787 to 0.14980, saving model to NNs/LSTM18-005.h5\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 9s 517us/step - loss: 0.1077 - acc: 0.9653 - val_loss: 0.1443 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14980 to 0.14429, saving model to NNs/LSTM18-006.h5\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 520us/step - loss: 0.0886 - acc: 0.9709 - val_loss: 0.1428 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14429 to 0.14284, saving model to NNs/LSTM18-007.h5\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 9s 520us/step - loss: 0.0718 - acc: 0.9765 - val_loss: 0.1623 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14284\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 503us/step - loss: 0.0703 - acc: 0.9775 - val_loss: 0.1536 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14284\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 511us/step - loss: 0.0631 - acc: 0.9810 - val_loss: 0.1691 - val_acc: 0.9468\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f81ec7f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM18_network()\n",
    "train_model('LSTM18', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM19_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(76)(layer)\n",
    "    layer = Dense(224,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_20 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_17 (CuDNNLSTM)    (None, 76)                38912     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 224)               17248     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 225       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,385\n",
      "Trainable params: 206,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 550us/step - loss: 0.3535 - acc: 0.8436 - val_loss: 0.1989 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19892, saving model to NNs/LSTM19-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 512us/step - loss: 0.2070 - acc: 0.9304 - val_loss: 0.2265 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19892\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 523us/step - loss: 0.1541 - acc: 0.9500 - val_loss: 0.1627 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19892 to 0.16274, saving model to NNs/LSTM19-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 502us/step - loss: 0.1357 - acc: 0.9557 - val_loss: 0.2120 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16274\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 9s 522us/step - loss: 0.1208 - acc: 0.9595 - val_loss: 0.2244 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16274\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 9s 521us/step - loss: 0.1119 - acc: 0.9638 - val_loss: 0.1681 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16274\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 522us/step - loss: 0.0921 - acc: 0.9716 - val_loss: 0.1694 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16274\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 508us/step - loss: 0.0845 - acc: 0.9719 - val_loss: 0.1362 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.16274 to 0.13623, saving model to NNs/LSTM19-008.h5\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 511us/step - loss: 0.0751 - acc: 0.9751 - val_loss: 0.2028 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13623\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 9s 514us/step - loss: 0.0654 - acc: 0.9799 - val_loss: 0.1579 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f30b6b38>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM19_network()\n",
    "train_model('LSTM19', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM20_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(76)(layer)\n",
    "    layer = Dense(296,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_18 (CuDNNLSTM)    (None, 76)                38912     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 296)               22792     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 296)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 296)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 297       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 212,001\n",
      "Trainable params: 212,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 547us/step - loss: 0.3630 - acc: 0.8424 - val_loss: 0.2146 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21464, saving model to NNs/LSTM20-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 520us/step - loss: 0.1996 - acc: 0.9297 - val_loss: 0.1578 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21464 to 0.15777, saving model to NNs/LSTM20-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 525us/step - loss: 0.1709 - acc: 0.9430 - val_loss: 0.1724 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15777\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 9s 518us/step - loss: 0.1543 - acc: 0.9495 - val_loss: 0.1752 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15777\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 9s 521us/step - loss: 0.1282 - acc: 0.9566 - val_loss: 0.1960 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15777\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 9s 522us/step - loss: 0.1212 - acc: 0.9606 - val_loss: 0.1555 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15777 to 0.15554, saving model to NNs/LSTM20-006.h5\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 523us/step - loss: 0.1051 - acc: 0.9662 - val_loss: 0.1612 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15554\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 9s 520us/step - loss: 0.0957 - acc: 0.9699 - val_loss: 0.1834 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15554\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 9s 515us/step - loss: 0.0893 - acc: 0.9716 - val_loss: 0.1847 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15554\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 506us/step - loss: 0.0839 - acc: 0.9733 - val_loss: 0.1535 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.15554 to 0.15353, saving model to NNs/LSTM20-010.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f3433cc0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM20_network()\n",
    "train_model('LSTM20', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM21_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(76)(layer)\n",
    "    layer = Dense(274,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_22 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_19 (CuDNNLSTM)    (None, 76)                38912     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 274)               21098     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 274)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 274)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 275       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 210,285\n",
      "Trainable params: 210,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 10s 574us/step - loss: 0.3691 - acc: 0.8406 - val_loss: 0.2557 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25571, saving model to NNs/LSTM21-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 9s 528us/step - loss: 0.1896 - acc: 0.9299 - val_loss: 0.1722 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25571 to 0.17218, saving model to NNs/LSTM21-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 9s 524us/step - loss: 0.1650 - acc: 0.9388 - val_loss: 0.1740 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17218\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 9s 519us/step - loss: 0.1377 - acc: 0.9537 - val_loss: 0.2163 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17218\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 501us/step - loss: 0.1253 - acc: 0.9586 - val_loss: 0.1511 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17218 to 0.15111, saving model to NNs/LSTM21-005.h5\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 504us/step - loss: 0.1123 - acc: 0.9632 - val_loss: 0.1524 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15111\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 9s 523us/step - loss: 0.1079 - acc: 0.9654 - val_loss: 0.1726 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15111\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 9s 520us/step - loss: 0.0880 - acc: 0.9713 - val_loss: 0.2017 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15111\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 9s 519us/step - loss: 0.0850 - acc: 0.9737 - val_loss: 0.1786 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15111\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 9s 525us/step - loss: 0.0827 - acc: 0.9726 - val_loss: 0.1520 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f1fb0d68>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM21_network()\n",
    "train_model('LSTM21', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM22_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(64,name='FC2')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_25 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_22 (CuDNNLSTM)    (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 64)                12608     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 205,109\n",
      "Trainable params: 205,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 536us/step - loss: 0.3733 - acc: 0.8434 - val_loss: 0.2198 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21984, saving model to NNs/LSTM22-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.1933 - acc: 0.9288 - val_loss: 0.1706 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21984 to 0.17064, saving model to NNs/LSTM22-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 478us/step - loss: 0.1672 - acc: 0.9438 - val_loss: 0.1463 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17064 to 0.14633, saving model to NNs/LSTM22-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 480us/step - loss: 0.1282 - acc: 0.9575 - val_loss: 0.1494 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14633\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.1172 - acc: 0.9619 - val_loss: 0.1470 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14633\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 464us/step - loss: 0.1087 - acc: 0.9662 - val_loss: 0.1547 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14633\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 455us/step - loss: 0.0996 - acc: 0.9675 - val_loss: 0.1391 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14633 to 0.13913, saving model to NNs/LSTM22-007.h5\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 7s 445us/step - loss: 0.0814 - acc: 0.9750 - val_loss: 0.1922 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13913\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 477us/step - loss: 0.0712 - acc: 0.9768 - val_loss: 0.1695 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13913\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 477us/step - loss: 0.0688 - acc: 0.9789 - val_loss: 0.1656 - val_acc: 0.9586\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f173f8d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM22_network()\n",
    "train_model('LSTM22', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM23_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(196,name='FC2')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_26 (Embedding)     (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_23 (CuDNNLSTM)    (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 64)                12608     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 205,109\n",
      "Trainable params: 205,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 535us/step - loss: 0.3834 - acc: 0.8349 - val_loss: 0.1982 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19816, saving model to NNs/LSTM22-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 7s 449us/step - loss: 0.1985 - acc: 0.9283 - val_loss: 0.2032 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19816\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 471us/step - loss: 0.1599 - acc: 0.9464 - val_loss: 0.1517 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19816 to 0.15166, saving model to NNs/LSTM22-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 479us/step - loss: 0.1341 - acc: 0.9563 - val_loss: 0.1694 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15166\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 473us/step - loss: 0.1143 - acc: 0.9627 - val_loss: 0.1467 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15166 to 0.14671, saving model to NNs/LSTM22-005.h5\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.0972 - acc: 0.9690 - val_loss: 0.1421 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14671 to 0.14209, saving model to NNs/LSTM22-006.h5\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 473us/step - loss: 0.0930 - acc: 0.9704 - val_loss: 0.1513 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14209\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.0776 - acc: 0.9732 - val_loss: 0.1697 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14209\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 470us/step - loss: 0.0634 - acc: 0.9806 - val_loss: 0.1669 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14209\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 474us/step - loss: 0.0559 - acc: 0.9829 - val_loss: 0.1897 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4f03654e0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM22_network()\n",
    "train_model('LSTM22', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM13_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 192,633\n",
      "Trainable params: 192,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value FC1/bias\n\t [[{{node FC1/bias/read}}]]\n\t [[{{node loss/mul}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-861b2a713405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM13_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM114'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-dbaa8f950e84>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_id, model, optimizer, epochs, X_train, y_train, validation_split, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtb_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./logs/nn_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value FC1/bias\n\t [[{{node FC1/bias/read}}]]\n\t [[{{node loss/mul}}]]"
     ]
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM114', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTMtest_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 179,761\n",
      "Trainable params: 179,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 16s 982us/step - loss: 0.3942 - acc: 0.8274 - val_loss: 0.2884 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28843, saving model to NNs/LSTMtest-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 467us/step - loss: 0.2067 - acc: 0.9285 - val_loss: 0.1621 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28843 to 0.16207, saving model to NNs/LSTMtest-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 477us/step - loss: 0.1752 - acc: 0.9420 - val_loss: 0.1664 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16207\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 479us/step - loss: 0.1511 - acc: 0.9503 - val_loss: 0.1542 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.16207 to 0.15421, saving model to NNs/LSTMtest-004.h5\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 479us/step - loss: 0.1344 - acc: 0.9560 - val_loss: 0.1582 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15421\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 472us/step - loss: 0.1255 - acc: 0.9573 - val_loss: 0.2247 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15421\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 7s 448us/step - loss: 0.1047 - acc: 0.9665 - val_loss: 0.1494 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15421 to 0.14938, saving model to NNs/LSTMtest-007.h5\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 7s 441us/step - loss: 0.0983 - acc: 0.9686 - val_loss: 0.1554 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14938\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 475us/step - loss: 0.0928 - acc: 0.9710 - val_loss: 0.2109 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14938\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 472us/step - loss: 0.0893 - acc: 0.9700 - val_loss: 0.1589 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcdbef656a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMtest_network()\n",
    "train_model('LSTMtest', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTMtest2_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,64,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(48)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1000, 64)          192000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 48)                21888     \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 49        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 213,937\n",
      "Trainable params: 213,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 8s 470us/step - loss: 0.3877 - acc: 0.8465 - val_loss: 0.2144 - val_acc: 0.9258\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21444, saving model to NNs/LSTMtest2-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 7s 444us/step - loss: 0.1871 - acc: 0.9338 - val_loss: 0.1655 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21444 to 0.16554, saving model to NNs/LSTMtest2-002.h5\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 7s 407us/step - loss: 0.1674 - acc: 0.9417 - val_loss: 0.1547 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16554 to 0.15465, saving model to NNs/LSTMtest2-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 7s 436us/step - loss: 0.1332 - acc: 0.9548 - val_loss: 0.1395 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15465 to 0.13949, saving model to NNs/LSTMtest2-004.h5\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 7s 448us/step - loss: 0.1176 - acc: 0.9617 - val_loss: 0.1481 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13949\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 7s 444us/step - loss: 0.1018 - acc: 0.9658 - val_loss: 0.1485 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13949\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 7s 447us/step - loss: 0.0978 - acc: 0.9693 - val_loss: 0.1465 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13949\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 7s 451us/step - loss: 0.0817 - acc: 0.9742 - val_loss: 0.1551 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13949\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 457us/step - loss: 0.0782 - acc: 0.9756 - val_loss: 0.1605 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13949\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 457us/step - loss: 0.0735 - acc: 0.9772 - val_loss: 0.1430 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcda4774550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMtest2_network()\n",
    "train_model('LSTMtest2', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
