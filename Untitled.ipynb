{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('NNs/LSTM13-002.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/train.csv')\n",
    "dataset.head()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_indexes = dataset.loc[pd.isna(dataset[\"text\"]), :].index\n",
    "dataset = dataset.drop(nan_indexes)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.text\n",
    "y = dataset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20761,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"tokenizer.pickle\",'rb')\n",
    "tokenizer = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_len = 1000\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras as K\n",
    "\n",
    "def train_model(model_id, model, optimizer, epochs, X_train, y_train, validation_split, batch_size):\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('NNs/' + model_id + '-{epoch:03d}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tb_callback = K.callbacks.TensorBoard(log_dir='./logs/nn_' + str(model_id))\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, callbacks=[tb_callback, checkpoint])\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM13_network():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = CuDNNLSTM(64)(layer)\n",
    "    layer = Dense(196,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import SimpleRNN, CuDNNLSTM, GRU, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "max_words = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 50)          150000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 196)               12740     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 197       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 192,633\n",
      "Trainable params: 192,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16608 samples, validate on 4153 samples\n",
      "Epoch 1/10\n",
      "16608/16608 [==============================] - 9s 525us/step - loss: 0.3797 - acc: 0.8345 - val_loss: 0.2276 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22756, saving model to NNs/LSTM114-001.h5\n",
      "Epoch 2/10\n",
      "16608/16608 [==============================] - 8s 467us/step - loss: 0.1860 - acc: 0.9339 - val_loss: 0.2282 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22756\n",
      "Epoch 3/10\n",
      "16608/16608 [==============================] - 8s 462us/step - loss: 0.1524 - acc: 0.9494 - val_loss: 0.1438 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22756 to 0.14379, saving model to NNs/LSTM114-003.h5\n",
      "Epoch 4/10\n",
      "16608/16608 [==============================] - 8s 459us/step - loss: 0.1303 - acc: 0.9559 - val_loss: 0.1368 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14379 to 0.13679, saving model to NNs/LSTM114-004.h5\n",
      "Epoch 5/10\n",
      "16608/16608 [==============================] - 8s 465us/step - loss: 0.1286 - acc: 0.9552 - val_loss: 0.1462 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13679\n",
      "Epoch 6/10\n",
      "16608/16608 [==============================] - 8s 463us/step - loss: 0.0955 - acc: 0.9689 - val_loss: 0.1852 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13679\n",
      "Epoch 7/10\n",
      "16608/16608 [==============================] - 8s 468us/step - loss: 0.1017 - acc: 0.9661 - val_loss: 0.3370 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13679\n",
      "Epoch 8/10\n",
      "16608/16608 [==============================] - 8s 467us/step - loss: 0.0852 - acc: 0.9718 - val_loss: 0.1689 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13679\n",
      "Epoch 9/10\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.0699 - acc: 0.9774 - val_loss: 0.1932 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13679\n",
      "Epoch 10/10\n",
      "16608/16608 [==============================] - 8s 469us/step - loss: 0.0662 - acc: 0.9798 - val_loss: 0.1395 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa9b72d7e10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM13_network()\n",
    "train_model('LSTM114', model, RMSprop(), 10, sequences_matrix, y, 0.2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20761/20761 [==============================] - 9s 440us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.058978520540837166, 0.9818409517587572]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(sequences_matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"test.model\",'wb')\n",
    "tokenizer = pickle.dump(model,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test = open('test.model', 'rb')\n",
    "model_test = pickle.load(file_test)\n",
    "file_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
